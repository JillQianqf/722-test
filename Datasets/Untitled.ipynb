{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365b9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file found at: Violence Against Women Girls Data.csv\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/ubuntu/722-test/aws-instance-fork/Datasets/Violence Against Women Girls Data.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file found at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# 这里你可以选择提前结束脚本，避免因文件不存在而抛出的异常\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# raise SystemExit(\"Stopping script.\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 如果文件存在，继续进行数据读取和操作\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 显示数据和模式\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py:410\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    408\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/ubuntu/722-test/aws-instance-fork/Datasets/Violence Against Women Girls Data.csv"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'Violence Against Women Girls Data.csv'\n",
    "\n",
    "# 确认文件是否存在\n",
    "import os\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File exists at: {file_path}\")\n",
    "else:\n",
    "    print(f\"No file found at: {file_path}\")\n",
    "    # 这里你可以选择提前结束脚本，避免因文件不存在而抛出的异常\n",
    "    # raise SystemExit(\"Stopping script.\")\n",
    "\n",
    "# 如果文件存在，继续进行数据读取和操作\n",
    "df = spark.read.csv(file_path, inferSchema=True, header=True)\n",
    "\n",
    "# 显示数据和模式\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d7e4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file='Violence Against Women  Girls Data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f00c0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RecordID      Country Gender Demographics Question  \\\n",
      "0             1  Afghanistan      F        Marital status   \n",
      "1             1  Afghanistan      F             Education   \n",
      "2             1  Afghanistan      F             Education   \n",
      "3             1  Afghanistan      F             Education   \n",
      "4             1  Afghanistan      F        Marital status   \n",
      "...         ...          ...    ...                   ...   \n",
      "12595       210     Zimbabwe      M             Residence   \n",
      "12596       280     Zimbabwe      M             Residence   \n",
      "12597       280     Zimbabwe      M             Residence   \n",
      "12598       350     Zimbabwe      M             Residence   \n",
      "12599       350     Zimbabwe      M             Residence   \n",
      "\n",
      "              Demographics Response                                 Question  \\\n",
      "0                     Never married                ... if she burns the food   \n",
      "1                            Higher                ... if she burns the food   \n",
      "2                         Secondary                ... if she burns the food   \n",
      "3                           Primary                ... if she burns the food   \n",
      "4      Widowed, divorced, separated                ... if she burns the food   \n",
      "...                             ...                                      ...   \n",
      "12595                         Urban  ... if she goes out without telling him   \n",
      "12596                         Rural         ... if she neglects the children   \n",
      "12597                         Urban         ... if she neglects the children   \n",
      "12598                         Rural  ... if she refuses to have sex with him   \n",
      "12599                         Urban  ... if she refuses to have sex with him   \n",
      "\n",
      "      Survey Year  Value  \n",
      "0      01/01/2015    NaN  \n",
      "1      01/01/2015   10.1  \n",
      "2      01/01/2015   13.7  \n",
      "3      01/01/2015   13.8  \n",
      "4      01/01/2015   13.8  \n",
      "...           ...    ...  \n",
      "12595  01/01/2015   11.8  \n",
      "12596  01/01/2015   20.1  \n",
      "12597  01/01/2015   15.0  \n",
      "12598  01/01/2015    7.2  \n",
      "12599  01/01/2015    3.7  \n",
      "\n",
      "[12600 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c76f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12600 entries, 0 to 12599\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   RecordID               12600 non-null  int64  \n",
      " 1   Country                12600 non-null  object \n",
      " 2   Gender                 12600 non-null  object \n",
      " 3   Demographics Question  12600 non-null  object \n",
      " 4   Demographics Response  12600 non-null  object \n",
      " 5   Question               12600 non-null  object \n",
      " 6   Survey Year            12600 non-null  object \n",
      " 7   Value                  11187 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 787.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape \n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b48992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(file, inferSchema=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a84d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------+---------------------+---------------------+--------------------+-----------+-----+\n",
      "|RecordID|    Country|Gender|Demographics Question|Demographics Response|            Question|Survey Year|Value|\n",
      "+--------+-----------+------+---------------------+---------------------+--------------------+-----------+-----+\n",
      "|       1|Afghanistan|     F|       Marital status|        Never married|... if she burns ...| 01/01/2015| null|\n",
      "|       1|Afghanistan|     F|            Education|               Higher|... if she burns ...| 01/01/2015| 10.1|\n",
      "|       1|Afghanistan|     F|            Education|            Secondary|... if she burns ...| 01/01/2015| 13.7|\n",
      "|       1|Afghanistan|     F|            Education|              Primary|... if she burns ...| 01/01/2015| 13.8|\n",
      "|       1|Afghanistan|     F|       Marital status| Widowed, divorced...|... if she burns ...| 01/01/2015| 13.8|\n",
      "|       1|Afghanistan|     F|           Employment|    Employed for kind|... if she burns ...| 01/01/2015| 17.0|\n",
      "|       1|Afghanistan|     F|                  Age|                15-24|... if she burns ...| 01/01/2015| 17.3|\n",
      "|       1|Afghanistan|     F|           Employment|           Unemployed|... if she burns ...| 01/01/2015| 18.0|\n",
      "|       1|Afghanistan|     F|            Residence|                Rural|... if she burns ...| 01/01/2015| 18.1|\n",
      "|       1|Afghanistan|     F|                  Age|                25-34|... if she burns ...| 01/01/2015| 18.2|\n",
      "|       1|Afghanistan|     F|       Marital status| Married or living...|... if she burns ...| 01/01/2015| 18.3|\n",
      "|       1|Afghanistan|     F|            Residence|                Urban|... if she burns ...| 01/01/2015| 18.3|\n",
      "|       1|Afghanistan|     F|                  Age|                35-49|... if she burns ...| 01/01/2015| 18.8|\n",
      "|       1|Afghanistan|     F|            Education|         No education|... if she burns ...| 01/01/2015| 19.1|\n",
      "|       1|Afghanistan|     F|           Employment|    Employed for cash|... if she burns ...| 01/01/2015| 20.8|\n",
      "|       1|Afghanistan|     M|       Marital status|        Never married|... if she burns ...| 01/01/2015| null|\n",
      "|       1|Afghanistan|     M|            Education|               Higher|... if she burns ...| 01/01/2015|  4.5|\n",
      "|       1|Afghanistan|     M|            Residence|                Urban|... if she burns ...| 01/01/2015|  4.6|\n",
      "|       1|Afghanistan|     M|           Employment|           Unemployed|... if she burns ...| 01/01/2015|  5.2|\n",
      "|       1|Afghanistan|     M|            Education|              Primary|... if she burns ...| 01/01/2015|  6.3|\n",
      "+--------+-----------+------+---------------------+---------------------+--------------------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a8d2170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Demographics Question: string (nullable = true)\n",
      " |-- Demographics Response: string (nullable = true)\n",
      " |-- Question: string (nullable = true)\n",
      " |-- Survey Year: string (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "075e7edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "|summary|          RecordID|    Country|Gender|Demographics Question|Demographics Response|            Question|Survey Year|             Value|\n",
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "|  count|             12600|      12600| 12600|                12600|                12600|               12600|      12600|             11187|\n",
      "|   mean|             210.5|       null|  null|                 null|                 null|                null|       null| 19.76253687315632|\n",
      "| stddev|121.24802439346753|       null|  null|                 null|                 null|                null|       null|16.986436699740587|\n",
      "|    min|                 1|Afghanistan|     F|                  Age|                15-24|... for at least ...| 01/01/2000|               0.0|\n",
      "|    max|               420|   Zimbabwe|     M|            Residence| Widowed, divorced...|... if she refuse...| 01/01/2018|              86.9|\n",
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77abaf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "|summary|          RecordID|    Country|Gender|Demographics Question|Demographics Response|            Question|Survey Year|             Value|\n",
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "|  count|             12600|      12600| 12600|                12600|                12600|               12600|      12600|             11187|\n",
      "|   mean|             210.5|       null|  null|                 null|                 null|                null|       null| 19.76253687315632|\n",
      "| stddev|121.24802439346753|       null|  null|                 null|                 null|                null|       null|16.986436699740587|\n",
      "|    min|                 1|Afghanistan|     F|                  Age|                15-24|... for at least ...| 01/01/2000|               0.0|\n",
      "|    max|               420|   Zimbabwe|     M|            Residence| Widowed, divorced...|... if she refuse...| 01/01/2018|              86.9|\n",
      "+-------+------------------+-----------+------+---------------------+---------------------+--------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1d2b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+------+----+----+\n",
      "|RecordID|count| mean|stddev| min| max|\n",
      "+--------+-----+-----+------+----+----+\n",
      "|     148|   15| 6.31|  2.47| 1.9|12.0|\n",
      "|     243|   28|20.00|  8.35| 2.4|34.3|\n",
      "|     392|   30|59.93| 18.82|16.6|83.3|\n",
      "|      31|   30| 3.81|  2.22| 0.4|10.8|\n",
      "|      85|   30|10.80|  5.35| 1.4|18.1|\n",
      "|     251|   30|14.55|  3.72| 7.4|21.2|\n",
      "|     137|   26| 3.34|  2.96| 0.4|13.0|\n",
      "|      65|   15|23.37|  8.86| 8.0|48.4|\n",
      "|     255|   30| 5.69|  2.44| 0.4|10.8|\n",
      "|      53|   15| 1.24|  0.43| 0.8| 2.2|\n",
      "|     296|   30|19.90|  8.16| 7.8|35.1|\n",
      "|     133|   30|14.25|  5.85| 3.9|26.4|\n",
      "|      78|   15| 5.45|  1.81| 1.7| 9.3|\n",
      "|     322|   30|40.31| 20.76| 3.1|66.7|\n",
      "|     362|   30|41.14|  8.06|13.7|53.9|\n",
      "|     321|   30| 7.80|  3.55| 1.7|16.7|\n",
      "|     375|   30|44.70| 15.55|15.4|72.7|\n",
      "|     155|   30|17.38| 11.29| 2.7|34.0|\n",
      "|     108|   30|25.15|  8.48| 8.8|38.8|\n",
      "|     211|   28|36.43| 11.30|19.6|50.6|\n",
      "+--------+-----+-----+------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, mean, stddev, min, max, format_number\n",
    "\n",
    "df_grouped = df.groupBy(\"RecordID\").agg(\n",
    "    count(\"Value\").alias(\"count\"),\n",
    "    format_number(mean(\"Value\"), 2).alias(\"mean\"),\n",
    "    format_number(stddev(\"Value\"), 2).alias(\"stddev\"),\n",
    "    min(\"Value\").alias(\"min\"),\n",
    "    max(\"Value\").alias(\"max\")\n",
    ")\n",
    "\n",
    "# result\n",
    "df_grouped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16418e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330e787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
